{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBP9PAZrxlM7",
        "outputId": "cbcbf197-b438-46df-d7f8-1c5fad293af7"
      },
      "id": "KBP9PAZrxlM7",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab 환경에서 진행하기 때문에 google drive 연결\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Me89cjnqwLmP",
        "outputId": "1fade49b-2b4d-43ef-9218-f7a6696c9ceb"
      },
      "id": "Me89cjnqwLmP",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5b18fde6",
      "metadata": {
        "id": "5b18fde6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class MultiHeadSelfAttention(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads #Multi-head Attention에서는 query, key, value를 바로 사용하는 것이 아닌 h번의 Linear projection을 따라 서로 다른 representation의 조합으로부터 Attention을 계산하는 방법이다. \n",
        "        self.query_dense = layers.Dense(embed_dim) #쿼리\n",
        "        self.key_dense = layers.Dense(embed_dim) #키\n",
        "        self.value_dense = layers.Dense(embed_dim) #밸류\n",
        "        self.combine_heads = layers.Dense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True) #Q와 V를 곱한다.\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) #텐서를 새로운 자료형으로 변환합니다.(tf.shape(key)[-1] = 차원)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key) #Sclae 작업, K차원의 루트값으로\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1) #Softmax\n",
        "        output = tf.matmul(weights, value) #V 곱하기\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) #Multihead Attention\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3]) #x를 전치합니다. perm에 따라 차원의 순서를 구성합니다.\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0] #배치크기 \n",
        "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(\n",
        "            query, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim) => tf.transpose(x, perm=[0, 2, 1, 3])의 결과\n",
        "        key = self.separate_heads(\n",
        "            key, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(\n",
        "            value, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value) #Self Attention\n",
        "        attention = tf.transpose(\n",
        "            attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.embed_dim)\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(\n",
        "            concat_attention\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dabd3198",
      "metadata": {
        "id": "dabd3198"
      },
      "source": [
        "## Transformer Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b91623d1",
      "metadata": {
        "id": "b91623d1"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs) #Multihead Attn 블록\n",
        "        attn_output = self.dropout1(attn_output, training=training) #드롭아웃\n",
        "        out1 = self.layernorm1(inputs + attn_output) #LM + Residual\n",
        "        ffn_output = self.ffn(out1) #FF 블록\n",
        "        ffn_output = self.dropout2(ffn_output, training=training) #드롭아웃\n",
        "        return self.layernorm2(out1 + ffn_output) #LM + Residual"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9aee4e41",
      "metadata": {
        "id": "9aee4e41"
      },
      "source": [
        "## Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8903cc0b",
      "metadata": {
        "id": "8903cc0b"
      },
      "outputs": [],
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, emded_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=emded_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=emded_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1) #포지션 정보\n",
        "        positions = self.pos_emb(positions) #포지션 임베딩\n",
        "        x = self.token_emb(x) #토큰임베딩\n",
        "        return x + positions #합치기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5211c80",
      "metadata": {
        "id": "a5211c80"
      },
      "source": [
        "## 데이터셋 준비 및 전처리"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/Deep_Learning/NLP/finance_sentiment_corpus-main/finance_data.csv',encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "myedAJ3vtnxs"
      },
      "id": "myedAJ3vtnxs",
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eoHCBOArwldc",
        "outputId": "d5f5f185-5bfe-4b10-ac08-5bf16c27271a"
      },
      "id": "eoHCBOArwldc",
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     labels                                           sentence  \\\n",
              "0   neutral  According to Gran, the company has no plans to...   \n",
              "1   neutral  Technopolis plans to develop in stages an area...   \n",
              "2  negative  The international electronic industry company ...   \n",
              "3  positive  With the new production plant the company woul...   \n",
              "4  positive  According to the company's updated strategy fo...   \n",
              "\n",
              "                                        kor_sentence  \n",
              "0  Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...  \n",
              "1  테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...  \n",
              "2  국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...  \n",
              "3  새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...  \n",
              "4  2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46335eb1-5849-4838-9878-b19c2c6d70e9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>sentence</th>\n",
              "      <th>kor_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>According to Gran, the company has no plans to...</td>\n",
              "      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "      <td>새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>According to the company's updated strategy fo...</td>\n",
              "      <td>2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46335eb1-5849-4838-9878-b19c2c6d70e9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46335eb1-5849-4838-9878-b19c2c6d70e9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46335eb1-5849-4838-9878-b19c2c6d70e9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_analysis(data):\n",
        "  if data == 'negative':\n",
        "    return 0\n",
        "  elif data == 'neutral':\n",
        "    return 1\n",
        "  else:\n",
        "    return 2"
      ],
      "metadata": {
        "id": "KaXX1IaRxEEM"
      },
      "id": "KaXX1IaRxEEM",
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['labels_tr'] = data['labels'].apply(lambda x: sentiment_analysis(x))"
      ],
      "metadata": {
        "id": "hTRgmSiSxE8U"
      },
      "id": "hTRgmSiSxE8U",
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[['kor_sentence','labels_tr']]\n",
        "data = [[i, j] for i, j in zip(data['kor_sentence'], data['labels_tr'])]"
      ],
      "metadata": {
        "id": "uxmfnPA3xIoV"
      },
      "id": "uxmfnPA3xIoV",
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/NLP_Practice/'"
      ],
      "metadata": {
        "id": "PRQdDtAdxMNj"
      },
      "id": "PRQdDtAdxMNj",
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "# vocab loading\n",
        "vocab_file = f\"{data_dir}kowiki.model\"\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(vocab_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdx7_tdlxjSk",
        "outputId": "7cb811ff-2915-440b-c669-808d31ee09fe"
      },
      "id": "pdx7_tdlxjSk",
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "arr_data = np.array(data)"
      ],
      "metadata": {
        "id": "PaBBaAsGx5q1"
      },
      "id": "PaBBaAsGx5q1",
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = []\n",
        "for idx in range(len(arr_data)):\n",
        "  vec = vocab.encode(arr_data[idx,0])\n",
        "  lst.append(vec)"
      ],
      "metadata": {
        "id": "jZYnhqInx0HX"
      },
      "id": "jZYnhqInx0HX",
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr_lst = np.array(lst).reshape(-1,).tolist()\n",
        "arr_label = np.array(data)[:,1].tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXeJgwhezyCf",
        "outputId": "faf16bba-c269-47c3-b8cb-f7c7be42b804"
      },
      "id": "ZXeJgwhezyCf",
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-156-5cadd6c037c5>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr_lst = np.array(lst).reshape(-1,).tolist()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr_label = list( map(lambda x: int(x) , arr_label ) )"
      ],
      "metadata": {
        "id": "G5v44koZ7Qyi"
      },
      "id": "G5v44koZ7Qyi",
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "id": "3d3adca6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d3adca6",
        "outputId": "05b0ef86-895e-4912-9d87-ad9b29f7915b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3876 Training sequences\n",
            "970 Validation sequences\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(arr_lst,arr_label,test_size = 0.2, random_state=0) #데이터셋 로딩\n",
        "print(len(x_train), \"Training sequences\")\n",
        "print(len(x_val), \"Validation sequences\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = keras.preprocessing.sequence.pad_sequences(x_train,maxlen=maxlen)#패딩\n",
        "x_val = keras.preprocessing.sequence.pad_sequences(x_val,maxlen=maxlen)#패딩"
      ],
      "metadata": {
        "id": "SJ1sJDmPsUZd"
      },
      "id": "SJ1sJDmPsUZd",
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.array(y_train)\n",
        "y_val = np.array(y_val)"
      ],
      "metadata": {
        "id": "vfsv7ma185zJ"
      },
      "id": "vfsv7ma185zJ",
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "af16c7f6",
      "metadata": {
        "id": "af16c7f6"
      },
      "source": [
        "## 모델 구축"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "id": "3496d964",
      "metadata": {
        "id": "3496d964"
      },
      "outputs": [],
      "source": [
        "embed_dim = 32  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "inputs = layers.Input(shape=(maxlen,)) #처음 입력\n",
        "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim) #객체 생성\n",
        "x = embedding_layer(inputs)  #포지셔널 임베딩\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim) #객체 생성\n",
        "x = transformer_block(x) #트랜스포머 \n",
        "x = layers.GlobalAveragePooling1D()(x) #Average Pooling\n",
        "x = layers.Dropout(0.1)(x) #드롯아웃\n",
        "x = layers.Dense(20, activation=\"relu\")(x) #FFNN\n",
        "x = layers.Dropout(0.1)(x) #드롭아웃\n",
        "outputs = layers.Dense(3, activation=\"softmax\")(x) #Softmax\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs) #모델 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb449082",
      "metadata": {
        "id": "fb449082"
      },
      "source": [
        "## 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "id": "7dfe5195",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dfe5195",
        "outputId": "d85dfa8b-b8a8-4326-a7d6-2cfbc9ba22b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "122/122 [==============================] - 11s 66ms/step - loss: 0.9359 - accuracy: 0.5800 - val_loss: 0.9267 - val_accuracy: 0.6021\n",
            "Epoch 2/5\n",
            "122/122 [==============================] - 7s 60ms/step - loss: 0.8450 - accuracy: 0.6373 - val_loss: 0.7569 - val_accuracy: 0.6711\n",
            "Epoch 3/5\n",
            "122/122 [==============================] - 7s 54ms/step - loss: 0.6379 - accuracy: 0.7371 - val_loss: 0.6509 - val_accuracy: 0.7278\n",
            "Epoch 4/5\n",
            "122/122 [==============================] - 7s 60ms/step - loss: 0.4657 - accuracy: 0.8313 - val_loss: 0.6602 - val_accuracy: 0.7258\n",
            "Epoch 5/5\n",
            "122/122 [==============================] - 7s 54ms/step - loss: 0.3243 - accuracy: 0.8880 - val_loss: 0.7552 - val_accuracy: 0.7629\n"
          ]
        }
      ],
      "source": [
        "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train, batch_size=32, epochs=5, validation_data=(x_val, y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e87ca46d",
      "metadata": {
        "id": "e87ca46d"
      },
      "source": [
        "## 성능측정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "id": "77fbc45d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77fbc45d",
        "outputId": "67796907-c191-44f2-e20e-cf5e437d9649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 200)]             0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, 200, 32)          646400    \n",
            " g_10 (TokenAndPositionEmbed                                     \n",
            " ding)                                                           \n",
            "                                                                 \n",
            " transformer_block_10 (Trans  (None, 200, 32)          6464      \n",
            " formerBlock)                                                    \n",
            "                                                                 \n",
            " global_average_pooling1d_10  (None, 32)               0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 20)                660       \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 20)                0         \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 3)                 63        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 653,587\n",
            "Trainable params: 653,587\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.7552 - accuracy: 0.7629\n",
            "Test_acc:  0.7628865838050842\n"
          ]
        }
      ],
      "source": [
        "#모델 정보 출력\n",
        "model.summary() \n",
        "\n",
        "#성능 측정\n",
        "test_loss,test_acc=model.evaluate(x_val,y_val)\n",
        "print(\"Test_acc: \",test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8b29b16d",
      "metadata": {
        "id": "8b29b16d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f76bf5d1",
      "metadata": {
        "id": "f76bf5d1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9de298bc",
      "metadata": {
        "id": "9de298bc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "624124c2",
      "metadata": {
        "id": "624124c2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}