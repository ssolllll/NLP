{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1491da3a",
      "metadata": {
        "id": "1491da3a"
      },
      "source": [
        "## Import Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "UuUo5xZYuElY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuUo5xZYuElY",
        "outputId": "0b76cba5-5b6f-47c0-dfdf-88013fa6be61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.1-py3-none-any.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.2-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.2 tokenizers-0.13.2 transformers-4.27.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "cdf99e5b",
      "metadata": {
        "id": "cdf99e5b"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import torch\n",
        "from torch.utils.data import Dataset, random_split\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer,  AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cdd7a96b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdd7a96b",
        "outputId": "31675962-d0c7-4dc2-dc0b-c7bcb97ba9c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cc733a92",
      "metadata": {
        "id": "cc733a92"
      },
      "outputs": [],
      "source": [
        "# pretrained된 tokneizer & model \n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2').to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "67ce2e6f",
      "metadata": {
        "id": "67ce2e6f"
      },
      "outputs": [],
      "source": [
        "# Defining Dataset\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, file_path):\n",
        "        # Load your data from a file or other source\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            self.data = f.read().splitlines()\n",
        "\n",
        "        # Tokenize the data using the GPT-2 tokenizer\n",
        "        from transformers import GPT2Tokenizer\n",
        "        self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "        self.tokenized_data = [self.tokenizer.encode(text) for text in self.data]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokenized_data) - 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_ids = self.tokenized_data[idx][:-1]\n",
        "        target_ids = self.tokenized_data[idx][1:]\n",
        "        return torch.tensor(input_ids), torch.tensor(target_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "70d77c44",
      "metadata": {
        "id": "70d77c44"
      },
      "outputs": [],
      "source": [
        "# Define the collate function\n",
        "\n",
        "def collate_fn(batch):\n",
        "    input_ids, target_ids = zip(*batch)\n",
        "    max_length = max(len(seq) for seq in input_ids)\n",
        "    padded_input_ids = torch.zeros(len(batch), max_length, dtype=torch.long)\n",
        "    padded_target_ids = torch.zeros(len(batch), max_length, dtype=torch.long)\n",
        "    for i, (input_seq, target_seq) in enumerate(zip(input_ids, target_ids)):\n",
        "        padded_input_ids[i, :len(input_seq)] = input_seq\n",
        "        padded_target_ids[i, :len(target_seq)] = target_seq\n",
        "    return padded_input_ids, padded_target_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "Z8CMbQHeuJvM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8CMbQHeuJvM",
        "outputId": "db4ce88e-a9b4-419a-a6bc-d0963bc21d8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "debdba78",
      "metadata": {
        "id": "debdba78"
      },
      "outputs": [],
      "source": [
        "train_file_path = 'drive/MyDrive/data/txt/chatbot.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "5d1b1389",
      "metadata": {
        "id": "5d1b1389"
      },
      "outputs": [],
      "source": [
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "3eee9e61",
      "metadata": {
        "id": "3eee9e61"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "dataset = MyDataset(train_file_path)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "ZOUbDL5X_iYc",
      "metadata": {
        "id": "ZOUbDL5X_iYc"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "1aD6osAn_kpF",
      "metadata": {
        "id": "1aD6osAn_kpF"
      },
      "outputs": [],
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,collate_fn=collate_fn )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "1306806a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1306806a",
        "outputId": "df1e0b28-e451-4ecb-da96-b30245e1f09c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# training settings\n",
        "\n",
        "num_epochs = 3\n",
        "learning_rate = 5e-5\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "c420a96d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c420a96d",
        "outputId": "ed91148f-0aaf-4323-bc8c-37f798f8a33a",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Batch: 100, Avg. Loss: 2.4022\n",
            "Epoch: 2, Batch: 100, Avg. Loss: 1.9481\n",
            "Epoch: 3, Batch: 100, Avg. Loss: 1.7844\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch_idx, (input_ids, target_ids) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = input_ids.to(device)\n",
        "        target_ids = target_ids.to(device)\n",
        "        outputs = model(input_ids, labels=target_ids)\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        if (batch_idx + 1) % 100 == 0:\n",
        "            avg_loss = total_loss / (batch_idx + 1)\n",
        "            print(f'Epoch: {epoch + 1}, Batch: {batch_idx + 1}, Avg. Loss: {avg_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1cf865b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cf865b6",
        "outputId": "415b39c3-80b3-41bf-aadf-6ebd99dbe9e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is the start of the generated text. you can to to to to to to!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "\n",
        "prompt = \"This is the start of the generated text.\"\n",
        "generated_text = tokenizer.encode(prompt)\n",
        "\n",
        "for i in range(100):\n",
        "    input_ids = torch.tensor(generated_text[-1024:]).unsqueeze(0)\n",
        "    input_ids = input_ids.to('cuda')\n",
        "    output = model(input_ids)\n",
        "    logits = output[0][:, -1, :]\n",
        "    new_token = torch.argmax(logits, dim=-1).item()\n",
        "    generated_text.append(new_token)\n",
        "generated_text = tokenizer.decode(generated_text)\n",
        "\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "xnLAhneZ_Ynk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnLAhneZ_Ynk",
        "outputId": "3af8f6d0-47c1-4354-c0aa-dad7f1ae069a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2023-03-16 05:58:35,435]\u001b[0m A new study created in memory with name: no-name-b55cb9dc-fd96-445a-a798-84e9fc54d082\u001b[0m\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2023-03-16 05:59:57,392]\u001b[0m Trial 0 finished with value: 0.6451632976531982 and parameters: {'learning_rate': 5.633187443248085e-05, 'num_train_epochs': 3, 'batch_size': 3}. Best is trial 0 with value: 0.6451632976531982.\u001b[0m\n",
            "\u001b[32m[I 2023-03-16 06:02:08,463]\u001b[0m Trial 1 finished with value: 0.3365764021873474 and parameters: {'learning_rate': 0.0003602476629430723, 'num_train_epochs': 5, 'batch_size': 31}. Best is trial 1 with value: 0.3365764021873474.\u001b[0m\n",
            "\u001b[32m[I 2023-03-16 06:05:35,726]\u001b[0m Trial 2 finished with value: 0.14394426345825195 and parameters: {'learning_rate': 0.0003868877642720656, 'num_train_epochs': 8, 'batch_size': 3}. Best is trial 2 with value: 0.14394426345825195.\u001b[0m\n",
            "\u001b[32m[I 2023-03-16 06:09:02,834]\u001b[0m Trial 3 finished with value: 0.3945985436439514 and parameters: {'learning_rate': 3.4092480519798124e-05, 'num_train_epochs': 8, 'batch_size': 6}. Best is trial 2 with value: 0.14394426345825195.\u001b[0m\n",
            "\u001b[32m[I 2023-03-16 06:12:55,184]\u001b[0m Trial 4 finished with value: 0.13939392566680908 and parameters: {'learning_rate': 0.00015320261153701007, 'num_train_epochs': 9, 'batch_size': 14}. Best is trial 4 with value: 0.13939392566680908.\u001b[0m\n",
            "\u001b[32m[I 2023-03-16 06:16:48,222]\u001b[0m Trial 5 finished with value: 0.4183919131755829 and parameters: {'learning_rate': 2.353385114063648e-05, 'num_train_epochs': 9, 'batch_size': 16}. Best is trial 4 with value: 0.13939392566680908.\u001b[0m\n",
            "\u001b[32m[I 2023-03-16 06:20:14,108]\u001b[0m Trial 6 finished with value: 0.5353586077690125 and parameters: {'learning_rate': 2.0638370366901174e-05, 'num_train_epochs': 8, 'batch_size': 2}. Best is trial 4 with value: 0.13939392566680908.\u001b[0m\n",
            "\u001b[32m[I 2023-03-16 06:23:39,869]\u001b[0m Trial 7 finished with value: 0.6434956789016724 and parameters: {'learning_rate': 1.1231819579674919e-05, 'num_train_epochs': 8, 'batch_size': 13}. Best is trial 4 with value: 0.13939392566680908.\u001b[0m\n",
            "\u001b[32m[I 2023-03-16 06:26:40,393]\u001b[0m Trial 8 finished with value: 0.3962201476097107 and parameters: {'learning_rate': 4.042836396030427e-05, 'num_train_epochs': 7, 'batch_size': 5}. Best is trial 4 with value: 0.13939392566680908.\u001b[0m\n",
            "\u001b[32m[I 2023-03-16 06:30:32,734]\u001b[0m Trial 9 finished with value: 0.21989011764526367 and parameters: {'learning_rate': 6.129374613715252e-05, 'num_train_epochs': 9, 'batch_size': 26}. Best is trial 4 with value: 0.13939392566680908.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial:\n",
            "  Loss: 0.139\n",
            "  Params: \n",
            "    learning_rate: 0.00015320261153701007\n",
            "    num_train_epochs: 9\n",
            "    batch_size: 14\n"
          ]
        }
      ],
      "source": [
        "def objective(trial):\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n",
        "    num_train_epochs = trial.suggest_int(\"num_train_epochs\", 1, 10)\n",
        "    batch_size = trial.suggest_int(\"batch_size\", 2, 32, log=True)\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    \n",
        "    best_loss = float('inf')\n",
        "    for epoch in range(num_train_epochs):\n",
        "        for batch in train_dataloader:\n",
        "            # Retrieve inputs and labels\n",
        "            inputs, labels = batch\n",
        "            # Move inputs and labels to device\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass\n",
        "            outputs = model(inputs, labels=labels)\n",
        "            # Compute loss\n",
        "            loss = outputs.loss\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            # Update weights\n",
        "            optimizer.step()\n",
        "            # Update best loss\n",
        "            if loss.item() < best_loss:\n",
        "                best_loss = loss.item()\n",
        "\n",
        "    return best_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04f95fac",
      "metadata": {},
      "outputs": [],
      "source": [
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "print(f\"  Loss: {trial.value:.3f}\")\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(f\"   {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "LocZ8LfvWLzC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LocZ8LfvWLzC",
        "outputId": "3bc82785-fecb-4409-c829-3ebdd86d8980"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_items([('learning_rate', 0.00015320261153701007), ('num_train_epochs', 9), ('batch_size', 14)])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trial.params.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "GN8PxZC-WW1v",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN8PxZC-WW1v",
        "outputId": "3b129103-6f12-458c-f635-9f75fed1bf5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# training settings\n",
        "\n",
        "num_epochs = 9\n",
        "learning_rate = 0.00015320261153701007\n",
        "batch_size = 14\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "0P1L0m4XqbzL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P1L0m4XqbzL",
        "outputId": "adaefdd8-6fbc-478a-edb3-490982560ce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Batch: 100, Avg. Loss: 1.7518\n",
            "Epoch: 2, Batch: 100, Avg. Loss: 1.4910\n",
            "Epoch: 3, Batch: 100, Avg. Loss: 1.2830\n",
            "Epoch: 4, Batch: 100, Avg. Loss: 1.0854\n",
            "Epoch: 5, Batch: 100, Avg. Loss: 0.9145\n",
            "Epoch: 6, Batch: 100, Avg. Loss: 0.7888\n",
            "Epoch: 7, Batch: 100, Avg. Loss: 0.6835\n",
            "Epoch: 8, Batch: 100, Avg. Loss: 0.5942\n",
            "Epoch: 9, Batch: 100, Avg. Loss: 0.5309\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch_idx, (input_ids, target_ids) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = input_ids.to(device)\n",
        "        target_ids = target_ids.to(device)\n",
        "        outputs = model(input_ids, labels=target_ids)\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        if (batch_idx + 1) % 100 == 0:\n",
        "            avg_loss = total_loss / (batch_idx + 1)\n",
        "            print(f'Epoch: {epoch + 1}, Batch: {batch_idx + 1}, Avg. Loss: {avg_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "uBnyoAqyqpYn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBnyoAqyqpYn",
        "outputId": "ee5ead4b-8c1b-47ba-e65f-53b2be3a7560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is the start of the generated text.!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "\n",
        "prompt = \"This is the start of the generated text.\"\n",
        "generated_text = tokenizer.encode(prompt)\n",
        "\n",
        "for i in range(100):\n",
        "    input_ids = torch.tensor(generated_text[-1024:]).unsqueeze(0)\n",
        "    input_ids = input_ids.to('cuda')\n",
        "    output = model(input_ids)\n",
        "    logits = output[0][:, -1, :]\n",
        "    new_token = torch.argmax(logits, dim=-1).item()\n",
        "    generated_text.append(new_token)\n",
        "generated_text = tokenizer.decode(generated_text)\n",
        "\n",
        "print(generated_text)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "68142b20",
      "metadata": {},
      "source": [
        "- Text Generation 기본 코드 예제를 찾아서 전체적인 코드를 진행해봄.\n",
        "- 추후 한글 데이터를 토대로 kogpt를 통해 만드는 것을 목표로 함."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
