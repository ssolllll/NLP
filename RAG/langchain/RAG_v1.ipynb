{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nì°¸ê³  ìë£Œ : LangChain Documents\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# package\n",
    "'''\n",
    "python-dotenv\n",
    "langchain\n",
    "langchain-openai\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "ì°¸ê³  ìë£Œ : LangChain Documents\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPENAI_API_KEY ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# í˜„ì¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ê²½ë¡œì™€ ipynb íŒŒì¼ ê²½ë¡œê°€ ë‹¬ë¼ í™˜ê²½ ê²½ë¡œ ì¼ì¹˜\n",
    "new_directory = './workspace/RAG'\n",
    "os.chdir(new_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "# .env íŒŒì¼ì— OPENAI_API_KEY=\"My_OPENAI_API_KEY\" ì‘ì„±\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langchainìœ¼ë¡œ êµ¬ì¶•í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ì—¬ëŸ¬ ë‹¨ê³„ì— ê±¸ì³ LLM í˜¸ì¶œì„ ì—¬ëŸ¬ ë²ˆ ì‚¬ìš©í•˜ê²Œ ë¨. <br>\n",
    "ì´ëŸ¬í•œ ì–´í”Œì´ ì ì  ë” ë³µì¡í•´ì§ì— ë”°ë¼, ì²´ì¸ì´ë‚˜ ì—ì´ì „íŠ¸ ë‚´ë¶€ì—ì„œ ì •í™•íˆ ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ”ì§€ ì¡°ì‚¬í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì´ ë§¤ìš° ì¤‘ìš”í•´ì§. <br>\n",
    "ì´ë¥¼ ìœ„í•œ ìµœì„ ì˜ ë°©ë²•ì€ LangSmithë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒ. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì²« ë²ˆì§¸ RAG ê¸°ë°˜ QA ë´‡\n",
    "\n",
    "ì²« ë²ˆì§¸ íŠœí† ë¦¬ì–¼ì—ëŠ” ë„¤ì´ë²„ ë‰´ìŠ¤ê¸°ì‚¬ì˜ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•  ìˆ˜ ìˆëŠ” ë‰´ìŠ¤ê¸°ì‚¬ QA ì•±ì„ êµ¬ì¶•í•¨\n",
    "ì´ ê°€ì´ë“œì—ì„œëŠ” OpenAI ì±— ëª¨ë¸ê³¼ ì„ë² ë”©, ê·¸ë¦¬ê³  Chroma ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì‚¬ìš©\n",
    "í•˜ì§€ë§Œ ì—¬ê¸°ì„œ ë³´ì—¬ì§€ëŠ” ëª¨ë“  ê²ƒì€ ì–´ë–¤ ChatModelì´ë‚˜ LLM, ì„ë² ë”©, ê·¸ë¦¬ê³  VectorStore ë˜ëŠ” Retrieverì™€ë„ ì‘ë™í•¨.\n",
    "ë¨¼ì € ë‹¤ìŒì˜ ê³¼ì •ì„ í†µí•´ ê°„ë‹¨í•œ ì¸ë±ì‹± íŒŒì´í”„ë¼ì¸ê³¼ RAG ì²´ì¸ì„ ì•½ 20ì¤„ì˜ ì½”ë“œë¡œ êµ¬í˜„í•  ìˆ˜ ìˆìŒ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "bs4,\n",
    "langchain : RecursiveCharacterTextSPlitter, ë¬¸ì„œ ë¡œë”©(WebBaseLoader), ë²¡í„° ì €ì¥(Chroma, FAISS)<br>\n",
    "ì¶œë ¥ íŒŒì‹±(StrOutputParser), ì‹¤í–‰ ê°€ëŠ¥í•œ íŒ¨ìŠ¤ìŠ¤ë£¨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./workspace/llm.md\")\n",
    "raw_doc = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import (\n",
    "    Language,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cpp',\n",
       " 'go',\n",
       " 'java',\n",
       " 'kotlin',\n",
       " 'js',\n",
       " 'ts',\n",
       " 'php',\n",
       " 'proto',\n",
       " 'python',\n",
       " 'rst',\n",
       " 'ruby',\n",
       " 'rust',\n",
       " 'scala',\n",
       " 'swift',\n",
       " 'markdown',\n",
       " 'latex',\n",
       " 'html',\n",
       " 'sol',\n",
       " 'csharp',\n",
       " 'cobol',\n",
       " 'c',\n",
       " 'lua',\n",
       " 'perl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e.value for e in Language]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nclass ', '\\ndef ', '\\n\\tdef ', '\\n\\n', '\\n', ' ', '']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RecursiveCharacterTextSplitter.get_separators_for_language(Language.PYTHON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='def hello_world():\\n    print(\"Hello, World!\")'),\n",
       " Document(page_content='# Call the function\\nhello_world()')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PYTHON_CODE = \"\"\"\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "\n",
    "# Call the function\n",
    "hello_world()\n",
    "\"\"\"\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
    ")\n",
    "python_docs = python_splitter.create_documents([PYTHON_CODE])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_text = \"\"\"\n",
    "# ğŸ¦œï¸ğŸ”— LangChain\n",
    "\n",
    "âš¡ Building applications with LLMs through composability âš¡\n",
    "\n",
    "## Quick Install\n",
    "\n",
    "```bash\n",
    "# Hopefully this code block isn't split\n",
    "pip install langchain\n",
    "```\n",
    "\n",
    "As an open-source project in a rapidly developing field, we are extremely open to contributions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='# ğŸ¦œï¸ğŸ”— LangChain'),\n",
       " Document(page_content='âš¡ Building applications with LLMs through composability âš¡'),\n",
       " Document(page_content='## Quick Install\\n\\n```bash'),\n",
       " Document(page_content=\"# Hopefully this code block isn't split\"),\n",
       " Document(page_content='pip install langchain'),\n",
       " Document(page_content='```'),\n",
       " Document(page_content='As an open-source project in a rapidly developing field, we'),\n",
       " Document(page_content='are extremely open to contributions.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.MARKDOWN, chunk_size=60, chunk_overlap=0\n",
    ")\n",
    "md_docs = md_splitter.create_documents([markdown_text])\n",
    "md_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass('your openai api key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
    "import os\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"your openai api key\"\n",
    "raw_documents = TextLoader(\"llm.md\").load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db = FAISS.from_documents(documents, OpenAIEmbeddings(openai_api_key=openai_api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1536)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(api_key=openai_api_key)\n",
    "\n",
    "embeddings = embeddings_model.embed_documents(\n",
    "    [\n",
    "        \"Hi there!\",\n",
    "        \"Oh, hello!\",\n",
    "        \"What's your name?\",\n",
    "        \"My friends call me World\",\n",
    "        \"Hello World!\"\n",
    "    ]\n",
    ")\n",
    "len(embeddings), len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.005384807424727807,\n",
       " -0.0005522561790177147,\n",
       " 0.03896066510130955,\n",
       " -0.002939867294003909,\n",
       " -0.008987877434176603]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_query = embeddings_model.embed_query(\"What was the name mentioned in the conversation?\")\n",
    "embedded_query[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
