{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VumZFL9jLO0I"
      },
      "source": [
        "# Chatbots with RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X43Jc0tLhn4"
      },
      "source": [
        "## 구조 Architectures\n",
        "\n",
        "1. 챗봇은 일반적으로 도메인 특화 질문에 더 잘 답하기 위해 개인 데이터에 대한 검색 강화 생성, 즉 RAG를 사용\n",
        "2. 최종 질문 답변을 위해 가장 관련성 높은 맥락만을 사용하도록 여러 데이터 소스 간에 경로를 설정할 수도 있고, 단순히 메시지를 주고받는 것 이상의 더 특화된 유형의 채팅 기록이나 메모리를 사용하기로 선택할 수도 있음."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeDxb6PlL4eI"
      },
      "source": [
        "## 구성 요소\n",
        "\n",
        "1. Chat Models : 챗봇 인터페이스는 원시 텍스트가 아닌 메시지를 기반으로 하기 때문에 텍스트 LLM보다는 채팅 모델에 더 적합합니다. 여기에서 채팅 모델 통합 목록을 보고, 여기에서 LangChain의 채팅 모델 인터페이스에 대한 문서를 확인하세요. 챗봇에 대해 LLM을 사용할 수도 있지만(여기를 참조), 채팅 모델은 더 대화적인 톤을 가지며 메시지 인터페이스를 기본적으로 지원합니다.\n",
        "\n",
        "2. Prompt Templates : 기본 메시지, 사용자 입력, 채팅 기록 및 (선택적으로) 추가 검색된 맥락을 결합하는 프롬프트를 조립하는 과정을 단순화함.\n",
        "\n",
        "3. Chat History : 챗봇이 과거 상호작용을 \"기억\"하고 후속 질문에 응답할 때 이를 고려할 수 있게 함.\n",
        "\n",
        "4.  Retrievers(선택사항) : 도메인 특화된 최신 지식을 맥락으로 사용하여 응답을 보강할 수 있는 챗봇을 구축하고 싶을 때 유용함."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "os.chdir('/workspace')\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvTRriBUNIyS",
        "outputId": "2c345211-03e1-45d4-e9e5-aeb20fa743fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "# import getpass\n",
        "# import os\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "281-UjrrL9AV"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38rKdykTMh44",
        "outputId": "f7c1c543-f73c-4892-aa41-d376d5b96ac0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Je aime le traitement du langage naturel.', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 41, 'total_tokens': 51}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_482d920018', 'finish_reason': 'stop', 'logprobs': None}, id='run-7f079ba9-297c-4516-9172-164bb4692c5c-0')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# 확인 결과 : 불어로 하면 이해 못하고 프랑스어로 해야 이해를 함.\n",
        "\n",
        "chat.invoke(\n",
        "    [\n",
        "        HumanMessage(\n",
        "            content=\"이 문장을 프랑스어로 번역해줄래? : 나는 자연어처리를 좋아합니다.\"\n",
        "        )\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV_Gs55IMntS",
        "outputId": "708b5cfc-530d-481b-b2ea-a7da0a6299bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='죄송합니다, 제가 무엇을 말했는지 기억하지 못합니다. 무엇을 도와드릴까요?', response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 18, 'total_tokens': 62}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_482d920018', 'finish_reason': 'stop', 'logprobs': None}, id='run-4eb73ae4-ff5d-47c6-9039-b369057f442e-0')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat.invoke([HumanMessage(content=\"뭐라고 말했어?\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BrgkqtUMurV",
        "outputId": "2bbb717b-e56a-4640-9c5b-bd6b604fae9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='\"Je suis passionné par le traitement du langage naturel.\" 라고 말했습니다. 이것은 \"나는 자연어처리를 좋아합니다.\" 라는 뜻입니다.', response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 73, 'total_tokens': 124}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_482d920018', 'finish_reason': 'stop', 'logprobs': None}, id='run-42d261f9-36bb-485f-a74c-eb37d5fca104-0')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import AIMessage\n",
        "\n",
        "chat.invoke(\n",
        "    [\n",
        "        HumanMessage(\n",
        "            content=\"이 문장을 프랑스어로 번역해줄래? : 나는 자연어처리를 좋아합니다.\"\n",
        "        ),\n",
        "        AIMessage(content=\"Je suis passionné par le traitement du langage naturel.\"),\n",
        "        HumanMessage(content=\"뭐라고 말했어?\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrLHQe1MJcQk"
      },
      "source": [
        "chat.invoke안에 context를 다 넣어야 전 내용을 받아 이어가는 것으로 보임."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "h61s2E0QM0qV"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\", # 'human', 'user', 'ai', 'assistant', or 'system'\n",
        "            \"넌 어시스턴트야. 모든 질문에 답을 해줘야 해.\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfxMUmUFM8Hy",
        "outputId": "f28f253b-9f42-4188-b208-35d786ad2531"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='I said \"Je suis passionné par le traitement du langage naturel,\" which means \"I am passionate about natural language processing\" in French.', response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 97, 'total_tokens': 127}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_b953e4de39', 'finish_reason': 'stop', 'logprobs': None}, id='run-3aac4a73-d41c-4dac-a4be-7bf8691fd6ed-0')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(\n",
        "                content=\"이 문장을 프랑스어로 번역해줄래? : 나는 자연어처리를 좋아합니다.\"\n",
        "            ),\n",
        "            AIMessage(content=\"Je suis passionné par le traitement du langage naturel.\"),\n",
        "            HumanMessage(content=\"What did you just say?\"),\n",
        "        ],\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9pI0vtEOE7s"
      },
      "source": [
        "## Message history\n",
        "\n",
        "1. 채팅기록 관리를 줄이는 방법론으로, MessageHistory class를 사용\n",
        "\n",
        "2. 채팅메시지 저장 및 로드 역할.\n",
        "\n",
        "3. 다양한 데이터베이스에 메시지를 지속시키는 내장 메시지 기록 통합 기능 존재.\n",
        "\n",
        "4. 하지만, 현재 Jupyter Notebook에서는 메모리 내에서 작동하는 데모 메시지 기록인 ChatMessageHistory를 사용."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oedi2mFHNF0y",
        "outputId": "2fc07d8a-661e-4962-e8de-1ffac7d4485f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='hi!'), AIMessage(content='whats up?')]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.memory import ChatMessageHistory\n",
        "\n",
        "\n",
        "demo_chat_history = ChatMessageHistory()\n",
        "demo_chat_history.add_user_message(\"hi!\")\n",
        "demo_chat_history.add_ai_message(\"whats up?\")\n",
        "demo_chat_history.messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "InMemoryChatMessageHistory(messages=[HumanMessage(content='hi!'), AIMessage(content='whats up?')])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo_chat_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS0MYLa2OGEk",
        "outputId": "0603e21a-faa9-46b3-e8cf-a7a49eb36369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='당연히요! \"나는 자연어처리를 좋아합니다.\"는 프랑스어로 \"J\\'aime le traitement du langage naturel.\"로 번역됩니다.', response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 84, 'total_tokens': 134}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_482d920018', 'finish_reason': 'stop', 'logprobs': None}, id='run-d04beaf8-3257-424a-b487-5004beae4b85-0')"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo_chat_history.add_user_message(\n",
        "    \"이 문장을 프랑스어로 번역해줄래? : 나는 자연어처리를 좋아합니다.\"\n",
        ")\n",
        "\n",
        "response = chain.invoke({\"messages\": demo_chat_history.messages})\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7qT_8E_OJGu",
        "outputId": "e74df206-ad7c-46dc-d254-7ddfbd6309e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='I said, \"J\\'aime le traitement du langage naturel,\" which means \"I like natural language processing\" in French.', response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 148, 'total_tokens': 175}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_482d920018', 'finish_reason': 'stop', 'logprobs': None}, id='run-e2b4c2ff-f84f-4ac2-8833-3fa2358b750a-0')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo_chat_history.add_ai_message(response)\n",
        "\n",
        "demo_chat_history.add_user_message(\"What did you just say?\")\n",
        "\n",
        "chain.invoke({\"messages\": demo_chat_history.messages})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku3kbvBsPsDq"
      },
      "source": [
        "## Retrievers\n",
        "\n",
        "1. 챗봇 도메인 특화 지식을 가져오기 위해 Retrievers를 설정할 수 있음.\n",
        "2. 위의 챗봇을 활용하여 LangSmith에 대한 질문에 답변할 수 있도록 할 수 있음.\n",
        "3. LangSmith 문서를 소스 자료로 사용하고 나중에 검색할 수 있또록 벡터 저장소에 저장할 것."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "oz_t7pxwPt2i"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "V-6P74zUQBdj"
      },
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
        "all_splits = text_splitter.split_documents(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "79cKQaCDQExT"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAMqHTdGQIuP",
        "outputId": "09c0e4ef-d5c5-4cb7-ea89-ce48968db823"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'}),\n",
              " Document(page_content='Skip to main contentLangSmith API DocsSearchGo to AppQuick StartUser GuideTracingEvaluationProduction Monitoring & AutomationsPrompt HubProxyPricingSelf-HostingCookbookQuick StartOn this pageGetting started with LangSmithIntroductionâ€‹LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!Install', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'}),\n",
              " Document(page_content='reach out to us at support@langchain.dev.My team deals with sensitive data that cannot be logged. How can I ensure that only my team can access it?â€‹If you are interested in a private deployment of LangSmith or if you need to self-host, please reach out to us at sales@langchain.dev. Self-hosting LangSmith requires an annual enterprise license that also comes with support and formalized access to the LangChain team.Was this page helpful?NextUser GuideIntroductionInstall LangSmithCreate an API', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'}),\n",
              " Document(page_content='lifecycle.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resourcesâ€‹LangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'})]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# k is the number of chunks to retrieve\n",
        "retriever = vectorstore.as_retriever(k=4)\n",
        "\n",
        "docs = retriever.invoke(\"how can langsmith help with testing?\")\n",
        "\n",
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIYeLXEaQd6T"
      },
      "source": [
        "Handling documents\n",
        "Let’s modify our previous prompt to accept documents as context. We’ll use a create_stuff_documents_chain helper function to “stuff” all of the input documents into the prompt, which also conveniently handles formatting. We use the ChatPromptTemplate.from_messages method to format the message input we want to pass to the model, including a MessagesPlaceholder where chat history messages will be directly injected:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6sMmuAjaQa89"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo-1106\")\n",
        "\n",
        "question_answering_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"Answer the user's questions based on the below context:\\n\\n{context}\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "document_chain = create_stuff_documents_chain(chat, question_answering_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "81jr8kGSQgrv",
        "outputId": "06339d85-1348-460d-a148-63e0e35c2f35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'LangSmith는 프로덕션급 LLM 애플리케이션을 구축하기 위한 플랫폼으로, 애플리케이션을 밀접하게 모니터링하고 평가하여 신속하고 확신을 갖고 배포할 수 있도록 도와줍니다. LangChain의 사용은 필요하지 않습니다 - LangSmith는 독립적으로 작동합니다. 또한 LangSmith를 사용하여 민감한 데이터를 로깅하지 않고, 팀 내에서만 접근할 수 있도록 보장할 수 있습니다. 자체 호스팅 옵션 또는 기업용 라이선스를 통해 LangSmith를 이용할 수 있습니다. LangSmith는 테스트 및 프로덕션 환경에서 도움을 줄 수 있습니다.'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.memory import ChatMessageHistory\n",
        "\n",
        "demo_chat_history = ChatMessageHistory()\n",
        "\n",
        "demo_chat_history.add_user_message(\"LangSmith는 테스트에 어떻게 도움이 될 수 있나요?\")\n",
        "\n",
        "document_chain.invoke(\n",
        "    {\n",
        "        \"messages\": demo_chat_history.messages,\n",
        "        \"context\": docs,\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QM6htYNQsrf"
      },
      "source": [
        "### Creating a retrieval chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "rSNA8Q36QntI"
      },
      "outputs": [],
      "source": [
        "from typing import Dict\n",
        "\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "\n",
        "def parse_retriever_input(params: Dict):\n",
        "    return params[\"messages\"][-1].content\n",
        "\n",
        "\n",
        "retrieval_chain = RunnablePassthrough.assign(\n",
        "    context=parse_retriever_input | retriever,\n",
        ").assign(\n",
        "    answer=document_chain,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmfmYPT4QuiJ",
        "outputId": "82102d57-cae6-4816-c73a-f18aa3d63f7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='LangSmith는 테스트에 어떻게 도움이 될 수 있나요?')],\n",
              " 'context': [Document(page_content='Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'}),\n",
              "  Document(page_content='Skip to main contentLangSmith API DocsSearchGo to AppQuick StartUser GuideTracingEvaluationProduction Monitoring & AutomationsPrompt HubProxyPricingSelf-HostingCookbookQuick StartOn this pageGetting started with LangSmithIntroductionâ€‹LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!Install', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'}),\n",
              "  Document(page_content='lifecycle.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resourcesâ€‹LangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'}),\n",
              "  Document(page_content='reach out to us at support@langchain.dev.My team deals with sensitive data that cannot be logged. How can I ensure that only my team can access it?â€‹If you are interested in a private deployment of LangSmith or if you need to self-host, please reach out to us at sales@langchain.dev. Self-hosting LangSmith requires an annual enterprise license that also comes with support and formalized access to the LangChain team.Was this page helpful?NextUser GuideIntroductionInstall LangSmithCreate an API', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'})],\n",
              " 'answer': 'LangSmith는 프로덕션급 LLM 응용 프로그램을 구축하기 위한 플랫폼으로, 응용 프로그램을 신속하고 자신 있게 출시할 수 있도록 모니터링 및 평가할 수 있습니다. LangSmith를 사용하면 LangChain이 필요하지 않으며, 독자적으로 작동합니다. 따라서 LangSmith를 사용하여 응용 프로그램의 성능 및 안정성을 테스트하고 개선할 수 있습니다.'}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = retrieval_chain.invoke(\n",
        "    {\n",
        "        \"messages\": demo_chat_history.messages,\n",
        "    }\n",
        ")\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ulj6vzHIQ_ac",
        "outputId": "dbba4b43-e176-45c3-bbe8-efcc95e67eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='LangSmith는 테스트에 어떻게 도움이 될 수 있나요?'),\n",
              "  AIMessage(content='LangSmith는 프로덕션급 LLM 응용 프로그램을 구축하기 위한 플랫폼으로, 응용 프로그램을 신속하고 자신 있게 출시할 수 있도록 모니터링 및 평가할 수 있습니다. LangSmith를 사용하면 LangChain이 필요하지 않으며, 독자적으로 작동합니다. 따라서 LangSmith를 사용하여 응용 프로그램의 성능 및 안정성을 테스트하고 개선할 수 있습니다.'),\n",
              "  HumanMessage(content='tell me more about that!'),\n",
              "  AIMessage(content='LangSmith는 프로덕션급 LLM 응용 프로그램을 구축하기 위한 플랫폼으로, 응용 프로그램을 신속하고 자신 있게 출시할 수 있도록 모니터링 및 평가할 수 있습니다. LangSmith를 사용하면 LangChain이 필요하지 않으며, 독자적으로 작동합니다. 따라서 LangSmith를 사용하여 응용 프로그램의 성능 및 안정성을 테스트하고 개선할 수 있습니다.'),\n",
              "  HumanMessage(content='tell me more about that!')],\n",
              " 'context': [Document(page_content=\"keySetup your environmentLog your first traceCreate your first evaluationNext StepsAdditional ResourcesFAQHow do I migrate projects between organizations?Why aren't my runs aren't showing up in my project?My team deals with sensitive data that cannot be logged. How can I ensure that only my team can access it?CommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright Â© 2024 LangChain, Inc.\", metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'}),\n",
              "  Document(page_content='lifecycle.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resourcesâ€‹LangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'}),\n",
              "  Document(page_content='Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'}),\n",
              "  Document(page_content='reach out to us at support@langchain.dev.My team deals with sensitive data that cannot be logged. How can I ensure that only my team can access it?â€‹If you are interested in a private deployment of LangSmith or if you need to self-host, please reach out to us at sales@langchain.dev. Self-hosting LangSmith requires an annual enterprise license that also comes with support and formalized access to the LangChain team.Was this page helpful?NextUser GuideIntroductionInstall LangSmithCreate an API', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'})],\n",
              " 'answer': 'LangSmith는 응용 프로그램의 품질과 성능을 평가하는 데 필요한 다양한 기능을 제공합니다. 이를 통해 실시간 추적, 평가 및 로깅이 가능하며, 응용 프로그램의 개선 사항을 식별하고 검증할 수 있습니다. 또한 LangSmith는 프로덕션 환경에서의 안정성과 확장성을 테스트하여 사용자 경험을 향상시키는 데 도움을 줄 수 있습니다. LangSmith를 사용하면 응용 프로그램을 개선하고 사용자들에게 더 나은 서비스를 제공할 수 있습니다.'}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo_chat_history.add_ai_message(response[\"answer\"])\n",
        "\n",
        "demo_chat_history.add_user_message(\"tell me more about that!\")\n",
        "\n",
        "retrieval_chain.invoke(\n",
        "    {\n",
        "        \"messages\": demo_chat_history.messages,\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "t3nTpklpRDPz",
        "outputId": "be1d043d-802e-4954-b380-a5f31ad975f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'LangSmith는 프로덕션급 LLM(언어 모델 라이프사이클) 응용 프로그램을 구축하는 데 도움을 주는 플랫폼입니다. 이를 통해 개발자들은 더 나은 언어 모델을 만들고 평가할 수 있으며, 안정성 및 성능을 향상시킬 수 있습니다. 또한, LangSmith는 자체적으로 작동하여 LangChain에 의존하지 않고 사용할 수 있습니다. 따라서 LangSmith를 사용하여 응용 프로그램의 성능 및 안정성을 테스트하고 개선할 수 있습니다.'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieval_chain_with_only_answer = (\n",
        "    RunnablePassthrough.assign(\n",
        "        context=parse_retriever_input | retriever,\n",
        "    )\n",
        "    | document_chain\n",
        ")\n",
        "\n",
        "retrieval_chain_with_only_answer.invoke(\n",
        "    {\n",
        "        \"messages\": demo_chat_history.messages,\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_cCd_pMRWiJ"
      },
      "source": [
        "Query transformation\n",
        "There’s one more optimization we’ll cover here - in the above example, when we asked a followup question, tell me more about that!, you might notice that the retrieved docs don’t directly include information about testing. This is because we’re passing tell me more about that! verbatim as a query to the retriever. The output in the retrieval chain is still okay because the document chain retrieval chain can generate an answer based on the chat history, but we could be retrieving more rich and informative documents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w-v29PXRLFD",
        "outputId": "bd390d4f-af49-4c63-a59b-4602e1b67c3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'}),\n",
              " Document(page_content='Skip to main contentLangSmith API DocsSearchGo to AppQuick StartUser GuideTracingEvaluationProduction Monitoring & AutomationsPrompt HubProxyPricingSelf-HostingCookbookQuick StartOn this pageGetting started with LangSmithIntroductionâ€‹LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!Install', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'}),\n",
              " Document(page_content='reach out to us at support@langchain.dev.My team deals with sensitive data that cannot be logged. How can I ensure that only my team can access it?â€‹If you are interested in a private deployment of LangSmith or if you need to self-host, please reach out to us at sales@langchain.dev. Self-hosting LangSmith requires an annual enterprise license that also comes with support and formalized access to the LangChain team.Was this page helpful?NextUser GuideIntroductionInstall LangSmithCreate an API', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'}),\n",
              " Document(page_content='lifecycle.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resourcesâ€‹LangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'})]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.invoke(\"how can langsmith help with testing?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_V8obAxRYB1",
        "outputId": "f2d8b701-8711-43e0-e8b6-84618acf7f8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content=\"keySetup your environmentLog your first traceCreate your first evaluationNext StepsAdditional ResourcesFAQHow do I migrate projects between organizations?Why aren't my runs aren't showing up in my project?My team deals with sensitive data that cannot be logged. How can I ensure that only my team can access it?CommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright Â© 2024 LangChain, Inc.\", metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'}),\n",
              " Document(page_content='lifecycle.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resourcesâ€‹LangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'}),\n",
              " Document(page_content='Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'}),\n",
              " Document(page_content='reach out to us at support@langchain.dev.My team deals with sensitive data that cannot be logged. How can I ensure that only my team can access it?â€‹If you are interested in a private deployment of LangSmith or if you need to self-host, please reach out to us at sales@langchain.dev. Self-hosting LangSmith requires an annual enterprise license that also comes with support and formalized access to the LangChain team.Was this page helpful?NextUser GuideIntroductionInstall LangSmithCreate an API', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'})]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.invoke(\"tell me more about that!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "M37IfhP6RZcm"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableBranch\n",
        "\n",
        "# We need a prompt that we can pass into an LLM to generate a transformed search query\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.2)\n",
        "\n",
        "query_transform_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        (\n",
        "            \"user\",\n",
        "            \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation. Only respond with the query, nothing else.\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "query_transforming_retriever_chain = RunnableBranch(\n",
        "    (\n",
        "        lambda x: len(x.get(\"messages\", [])) == 1,\n",
        "        # If only one message, then we just pass that message's content to retriever\n",
        "        (lambda x: x[\"messages\"][-1].content) | retriever,\n",
        "    ),\n",
        "    # If messages, then we pass inputs to LLM chain to transform the query, then pass to retriever\n",
        "    query_transform_prompt | chat | StrOutputParser() | retriever,\n",
        ").with_config(run_name=\"chat_retriever_chain\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "W7_Pp1w2RiKX"
      },
      "outputs": [],
      "source": [
        "document_chain = create_stuff_documents_chain(chat, question_answering_prompt)\n",
        "\n",
        "conversational_retrieval_chain = RunnablePassthrough.assign(\n",
        "    context=query_transforming_retriever_chain,\n",
        ").assign(\n",
        "    answer=document_chain,\n",
        ")\n",
        "\n",
        "demo_ephemeral_chat_history = ChatMessageHistory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P9tOYFHRkH-",
        "outputId": "968b96e9-0958-404d-8a9b-82b41d8fb595"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='how can langsmith help with testing?'),\n",
              "  AIMessage(content='LangSmith can help with testing by providing tracing, evaluation, and production monitoring capabilities for your LLM (Language Model) applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. With LangSmith, you can trace the behavior of your application, evaluate its performance, and monitor it in production to ensure everything is running smoothly. Additionally, LangSmith offers a Prompt Hub, a prompt management tool built into the platform, which can aid in testing and managing prompts for your language model. If you have specific testing requirements or need further assistance, feel free to reach out to the LangChain team at support@langchain.dev for more information.')],\n",
              " 'context': [Document(page_content='Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'}),\n",
              "  Document(page_content='Skip to main contentLangSmith API DocsSearchGo to AppQuick StartUser GuideTracingEvaluationProduction Monitoring & AutomationsPrompt HubProxyPricingSelf-HostingCookbookQuick StartOn this pageGetting started with LangSmithIntroductionâ€‹LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!Install', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'}),\n",
              "  Document(page_content='reach out to us at support@langchain.dev.My team deals with sensitive data that cannot be logged. How can I ensure that only my team can access it?â€‹If you are interested in a private deployment of LangSmith or if you need to self-host, please reach out to us at sales@langchain.dev. Self-hosting LangSmith requires an annual enterprise license that also comes with support and formalized access to the LangChain team.Was this page helpful?NextUser GuideIntroductionInstall LangSmithCreate an API', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'}),\n",
              "  Document(page_content='lifecycle.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resourcesâ€‹LangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'})],\n",
              " 'answer': 'LangSmith can help with testing by providing tracing, evaluation, and production monitoring capabilities for your LLM (Language Model) applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. With LangSmith, you can trace the behavior of your application, evaluate its performance, and monitor it in production to ensure everything is running smoothly. Additionally, LangSmith offers a Prompt Hub, a prompt management tool built into the platform, which can aid in testing and managing prompts for your language model. If you have specific testing requirements or need further assistance, feel free to reach out to the LangChain team at support@langchain.dev for more information.'}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo_ephemeral_chat_history.add_user_message(\"how can langsmith help with testing?\")\n",
        "\n",
        "response = conversational_retrieval_chain.invoke(\n",
        "    {\"messages\": demo_ephemeral_chat_history.messages},\n",
        ")\n",
        "\n",
        "demo_ephemeral_chat_history.add_ai_message(response[\"answer\"])\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPMstSCrRypu",
        "outputId": "7087b8be-a98c-4331-8f38-2bf47cd8bfb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='how can langsmith help with testing?'),\n",
              "  AIMessage(content='LangSmith can help with testing by providing tracing, evaluation, and production monitoring capabilities for your LLM (Language Model) applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. With LangSmith, you can trace the behavior of your application, evaluate its performance, and monitor it in production to ensure everything is running smoothly. Additionally, LangSmith offers a Prompt Hub, a prompt management tool built into the platform, which can aid in testing and managing prompts for your language model. If you have specific testing requirements or need further assistance, feel free to reach out to the LangChain team at support@langchain.dev for more information.'),\n",
              "  HumanMessage(content='tell me more about that!')],\n",
              " 'context': [Document(page_content='Skip to main contentLangSmith API DocsSearchGo to AppQuick StartUser GuideTracingEvaluationProduction Monitoring & AutomationsPrompt HubProxyPricingSelf-HostingCookbookQuick StartOn this pageGetting started with LangSmithIntroductionâ€‹LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!Install', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'}),\n",
              "  Document(page_content='Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'}),\n",
              "  Document(page_content='lifecycle.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resourcesâ€‹LangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using', metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'}),\n",
              "  Document(page_content=\"LangSmithâ€‹We offer Python and Typescript SDKs for all your LangSmith needs.PythonTypeScriptpip install -U langsmithyarn add langchain langsmithCreate an API keyâ€‹To create an API key head to the setting pages. Then click Create API Key.Setup your environmentâ€‹Shellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it's not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>Log your first traceâ€‹We provide\", metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'})],\n",
              " 'answer': \"Certainly! LangSmith provides tracing capabilities that allow you to track and analyze the behavior of your LLM applications. This can be useful for debugging, understanding how your model is performing, and identifying any issues or areas for improvement.\\n\\nIn addition, LangSmith offers evaluation capabilities, which enable you to assess the performance and accuracy of your language model. This can help you ensure that your model is producing the desired outputs and meeting your quality standards.\\n\\nFurthermore, LangSmith includes production monitoring features, which allow you to monitor the performance and behavior of your application in a live production environment. This can help you identify and address any issues that may arise during real-world usage.\\n\\nThe Prompt Hub, integrated into LangSmith, provides a tool for managing prompts, which can be helpful for testing and refining the prompts used to interact with your language model.\\n\\nOverall, LangSmith's comprehensive set of tools and capabilities can support your testing efforts by providing insights, monitoring, and management features for your LLM applications. If you have specific use cases or questions about how LangSmith can assist with your testing needs, please feel free to ask for more details.\"}"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo_ephemeral_chat_history.add_user_message(\"tell me more about that!\")\n",
        "\n",
        "conversational_retrieval_chain.invoke(\n",
        "    {\"messages\": demo_ephemeral_chat_history.messages}\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
